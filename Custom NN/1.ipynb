{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TrainData on our NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "wjYSR_w8gBxb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liorhirsch/Kaggle-Landmark-ML-Challange/blob/master/Custom%20NN/1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ovCIfYJru02G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Configuring the environment either to local or remote usage"
      ]
    },
    {
      "metadata": {
        "id": "sy6bXJaTuzzO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BASE_PATH='drive/My Drive'\n",
        "# BASE_PATH=\"E:/Projects/ML_Project/Landmark_Kaggle_Challange\"\n",
        "MODEL_NAME = \"1.0\"\n",
        "\n",
        "TRAINING_DATA_DIR = BASE_PATH + '/photos'\n",
        "VALIDATION_DATA_DIR = BASE_PATH + '/validation'\n",
        "TEST_DATA_PATH = BASE_PATH + '/test'\n",
        "\n",
        "MODEL_ENDING = \".H5\"\n",
        "\n",
        "RESULTS_PATH=BASE_PATH + \"/results/\"\n",
        "SAVING_DIR_PATH=BASE_PATH + \"/models/\"\n",
        "FULL_SAVING_PATH = SAVING_DIR_PATH + MODEL_NAME + MODEL_ENDING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjYSR_w8gBxb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload data from google drive"
      ]
    },
    {
      "metadata": {
        "id": "XM-4Y_2pgGwJ",
        "colab_type": "code",
        "outputId": "54c85bbf-fc3c-4e7b-a410-c57e7d256d05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y8EnxVkGgNqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build training data\n"
      ]
    },
    {
      "metadata": {
        "id": "Njiw9oQjgG83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbyGSja5O8VP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Augmentated Data Generation**\n",
        "\n",
        "Creates images generators both for the test and the training data, to create additional data"
      ]
    },
    {
      "metadata": {
        "id": "zi7O9h8zPh-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W--6UpdkNdQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "                              rotation_range=0,\n",
        "                              width_shift_range=0,\n",
        "                               height_shift_range=0,\n",
        "                               shear_range=0,\n",
        "                               zoom_range=[0.8, 1.25],\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=False,\n",
        "                               fill_mode='reflect',\n",
        "                               data_format='channels_last',\n",
        "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                               rotation_range=30,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               shear_range=0.01,\n",
        "                               zoom_range=[0.8, 1.25],\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=False,\n",
        "                               fill_mode='reflect',\n",
        "                               data_format='channels_last',\n",
        "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnVfTbjsP1vt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Uses the data as a stream object to enable batching on it instead of loading them all together to the ram using the ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "9VIoOKh5MuWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "53e8eaad-6edc-4c59-e3f6-db39e1b07568"
      },
      "cell_type": "code",
      "source": [
        "image_size = (100,100)\n",
        "batch_size = 25\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(TRAINING_DATA_DIR,\n",
        "                                                 target_size=image_size,\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                                        VALIDATION_DATA_DIR,\n",
        "                                         target_size=image_size,\n",
        "                                         color_mode='rgb',\n",
        "                                        class_mode = \"categorical\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 67559 images belonging to 100 classes.\n",
            "Found 7458 images belonging to 100 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I9qdrQW7A1kw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Validate the data"
      ]
    },
    {
      "metadata": {
        "id": "FpVCqwfgQWlo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "# print(x_batch) # RGB 2d array\n",
        "# print(y_batch) # The label (class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPZsMdzOQcWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(batch_size):\n",
        "    plt.subplot(5,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    image = x_batch[i]\n",
        "    image= image.astype(np.uint8)\n",
        "    plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YENKwn2gd7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build The Network"
      ]
    },
    {
      "metadata": {
        "id": "Fj9gq5NfgR41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8F-7H5-jskL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Normalize the images.**"
      ]
    },
    {
      "metadata": {
        "id": "1QHRjCbcgjCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_batch = x_batch/255.0\n",
        "# print(x_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OxDR9s8vi5zN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build the NN**"
      ]
    },
    {
      "metadata": {
        "id": "PwvyevDngjFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape = x_batch.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Flatening the data\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNr7qLyugjGq",
        "colab_type": "code",
        "outputId": "624e32d2-c213-49b5-aefc-d8b59c828713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 98, 98, 64)        1792      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 98, 98, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 49, 49, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 47, 47, 32)        18464     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16928)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 150)               2539350   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               15100     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 2,574,706\n",
            "Trainable params: 2,574,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kI8CcMtF7wsI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We convert the generator's output from binary array that contains 1 in the related class, to array contains the indexes of the classes for each picture in the batch"
      ]
    },
    {
      "metadata": {
        "id": "Lhc3bmSaPjJu",
        "colab_type": "code",
        "outputId": "0dac991d-4154-44e4-8f0c-87d35381f5e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# y=[a.tolist().index(1) for a in y_batch];\n",
        "# print(y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[32, 5, 12, 32, 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xoMiVWuDjRsU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "fpPYRBMgjsGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us configure a loss function and optimizer.\n",
        "\n",
        "The generator gives us in y a vector contains match percentages for each label, so we want to change it to show 0 or 1 using caregorical_crossentropy"
      ]
    },
    {
      "metadata": {
        "id": "Pg0VC_gnjj6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUzxicT-jueQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "we calculate the amount of batches in an ephoch (For fitting the model)"
      ]
    },
    {
      "metadata": {
        "id": "GAOigFXljyPx",
        "colab_type": "code",
        "outputId": "7b001df7-c9a7-4fbc-8a3c-943a025ee38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "print(step_size_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kdxhXhlFBt7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fix for the error : \n",
        "OSError: image file is truncated (14 bytes not processed)"
      ]
    },
    {
      "metadata": {
        "id": "gF5dHsZSBqEx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
        "\n",
        "#https://stackoverflow.com/questions/12984426/python-pil-ioerror-image-file-truncated-with-big-images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q7aI5NDurIrB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define an early stopper to avoid wasting compute resources and time"
      ]
    },
    {
      "metadata": {
        "id": "ppvNHi7krH7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2Fs2chOrPtw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "networkfileName = RESULTS_PATH + \"/\" + MODEL_NAME + \"{}\" + MODEL_ENDING.format(int(time.time()))\n",
        "                      \n",
        "checkpoint = ModelCheckpoint(networkfileName, monitor='val_acc', verbose=1,\n",
        "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HfysIFiHj6Rz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we train the model with fit_generator instead of regular fit."
      ]
    },
    {
      "metadata": {
        "id": "rIqYAT_Kj9lm",
        "colab_type": "code",
        "outputId": "32fa07a9-7bbc-4543-b595-9fc1fcbbfe04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train, # step=how much batches in one epoc\n",
        "                   validation_data = validation_generator,\n",
        "                   epochs=5\n",
        "                   ,callbacks = [checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "   17/13511 [..............................] - ETA: 40:52:03 - loss: 15.4734 - acc: 0.0400"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:872: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  543/13511 [>.............................] - ETA: 33:11:42 - loss: 15.7322 - acc: 0.0239"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2S_FBNGesa83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Examine the results"
      ]
    },
    {
      "metadata": {
        "id": "UFYpzSfRkL7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A8NihPX5sNL7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lkD2XN3VoN6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save the model"
      ]
    },
    {
      "metadata": {
        "id": "cerE2JXmgziv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create results directory if it doesn't exist"
      ]
    },
    {
      "metadata": {
        "id": "vg1XgLU6g3oT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(SAVING_DIR_PATH):\n",
        "    os.makedirs(SAVING_DIR_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sb-BkVPwoQnj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(FULL_SAVING_PATH)  # creates a HDF5 file 'my_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wa599XGW_IvC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the model from h5 file"
      ]
    },
    {
      "metadata": {
        "id": "LRcUZ2M_hOHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "load the model from the saved file"
      ]
    },
    {
      "metadata": {
        "id": "i52-Ozi5hNw7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "model = load_model(FULL_SAVING_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Isq0Db2goaYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nk3Nyobeoa-9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"loss: \",train_loss, \"acc: \",  train_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8dFWjonWnxUD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test the model on the TestSet"
      ]
    },
    {
      "metadata": {
        "id": "UELxNiCInm_s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets evaluate our model on the test set :\n"
      ]
    },
    {
      "metadata": {
        "id": "g_xQJ64Ngcq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(x_batch,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brNgZlmZsfUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator()\n",
        "test_generator=test_datagen.flow_from_directory(TEST_DATA_PATH,\n",
        "                                                  target_size=image_size,\n",
        "                                                  color_mode='rgb',\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical')\n",
        "\n",
        "step_size_test=test_generator.n//test_generator.batch_size\n",
        "\n",
        "test_loss, test_acc = model_final.evaluate_generator(generator=test_generator, \n",
        "                               steps=step_size_test)\n",
        "                               \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhC4eOeD-ON1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_loss)\n",
        "print(train_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
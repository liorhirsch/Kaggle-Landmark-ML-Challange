{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainData on our NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "wjYSR_w8gBxb"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liorhirsch/Kaggle-Landmark-ML-Challange/blob/master/Custom%20NN/Basic_Custom_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wjYSR_w8gBxb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload data from google drive"
      ]
    },
    {
      "metadata": {
        "id": "XM-4Y_2pgGwJ",
        "colab_type": "code",
        "outputId": "266f8e1d-fd26-40b9-9af5-b68b468b1007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y8EnxVkGgNqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build training data\n"
      ]
    },
    {
      "metadata": {
        "id": "Njiw9oQjgG83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbyGSja5O8VP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Augmentated Data Generation**\n",
        "\n",
        "Creates images generators both for the test and the training data, to create additional data"
      ]
    },
    {
      "metadata": {
        "id": "zi7O9h8zPh-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W--6UpdkNdQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "                              rotation_range=0,\n",
        "                              width_shift_range=0,\n",
        "                               height_shift_range=0,\n",
        "                               shear_range=0,\n",
        "                               zoom_range=[0.8, 1.25],\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=False,\n",
        "                               fill_mode='reflect',\n",
        "                               data_format='channels_last',\n",
        "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                               rotation_range=30,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               shear_range=0.01,\n",
        "                               zoom_range=[0.8, 1.25],\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=False,\n",
        "                               fill_mode='reflect',\n",
        "                               data_format='channels_last',\n",
        "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnVfTbjsP1vt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Uses the data as a stream object to enable batching on it instead of loading them all together to the ram using the ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "9VIoOKh5MuWo",
        "colab_type": "code",
        "outputId": "0c152203-d0d4-4087-f414-ae5b080b9b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "image_size = (100,100)\n",
        "batch_size = 20\n",
        "\n",
        "training_data_dir = 'drive/My Drive/photos'\n",
        "validation_data_dir = 'drive/My Drive/test'\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(training_data_dir,\n",
        "                                                 target_size=image_size,\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                                        validation_data_dir,\n",
        "                                         target_size=image_size,\n",
        "                                         color_mode='rgb',\n",
        "                                        class_mode = \"categorical\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 67559 images belonging to 100 classes.\n",
            "Found 18780 images belonging to 100 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FpVCqwfgQWlo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "# print(x_batch) # RGB 2d array\n",
        "# print(y_batch) # The label (class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPZsMdzOQcWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    image = x_batch[i]\n",
        "    image= image.astype(np.uint8)\n",
        "    plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YENKwn2gd7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build The Network"
      ]
    },
    {
      "metadata": {
        "id": "Fj9gq5NfgR41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8F-7H5-jskL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Normalize the images.**"
      ]
    },
    {
      "metadata": {
        "id": "1QHRjCbcgjCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_batch = x_batch/255.0\n",
        "# print(x_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OxDR9s8vi5zN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build the NN**"
      ]
    },
    {
      "metadata": {
        "id": "PwvyevDngjFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape = x_batch.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Flatening the data\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNr7qLyugjGq",
        "colab_type": "code",
        "outputId": "93b230d4-5cf7-4715-9078-caf42756b040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 98, 98, 64)        1792      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 98, 98, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 49, 49, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 47, 47, 32)        18464     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 47, 47, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16928)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 150)               2539350   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               15100     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 2,574,706\n",
            "Trainable params: 2,574,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ImGYYAj0jDX8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use Adam Optimizer to..."
      ]
    },
    {
      "metadata": {
        "id": "oaRupgnwgjIq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adamOptimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam',\\\n",
        "#  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kI8CcMtF7wsI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We convert the generator's output from binary array that contains 1 in the related class, to array contains the indexes of the classes for each picture in the batch"
      ]
    },
    {
      "metadata": {
        "id": "Lhc3bmSaPjJu",
        "colab_type": "code",
        "outputId": "6758bc51-3806-4769-ce1a-25a1ef39ef04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y=[a.tolist().index(1) for a in y_batch];\n",
        "print(y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[28, 10, 55, 77, 26, 0, 16, 33, 9, 50, 32, 3, 92, 7, 26, 15, 25, 64, 22, 76]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xoMiVWuDjRsU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "fpPYRBMgjsGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us configure a loss function and optimizer.\n",
        "\n",
        "The generator gives us in y a vector contains match percentages for each label, so we want to change it to show 0 or 1 using caregorical_crossentropy"
      ]
    },
    {
      "metadata": {
        "id": "Pg0VC_gnjj6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUzxicT-jueQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "we calculate the amount of batches in an ephoch (For fitting the model)"
      ]
    },
    {
      "metadata": {
        "id": "GAOigFXljyPx",
        "colab_type": "code",
        "outputId": "c6fe1389-ee33-4d6c-d868-9dce60edd88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "print(step_size_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rmchE3Avjzyl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We would like to observe the loss function values throught the training process. \n",
        "This is why we create a callback to store the loss and accuracy function values for each batch :"
      ]
    },
    {
      "metadata": {
        "id": "tlZzhz19j1Ny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LossAccHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.accuracy = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.accuracy.append(logs.get('acc'))\n",
        "        \n",
        "history = LossAccHistory()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kdxhXhlFBt7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fix for the error : \n",
        "OSError: image file is truncated (14 bytes not processed)"
      ]
    },
    {
      "metadata": {
        "id": "gF5dHsZSBqEx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
        "\n",
        "#https://stackoverflow.com/questions/12984426/python-pil-ioerror-image-file-truncated-with-big-images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HfysIFiHj6Rz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we train the model with fit_generator instead of regular fit."
      ]
    },
    {
      "metadata": {
        "id": "rIqYAT_Kj9lm",
        "colab_type": "code",
        "outputId": "b5b882fc-0567-439f-80d5-aee659a8d7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train, # step=how much batches in one epoc\n",
        "                   validation_data = validation_generator,\n",
        "                   epochs=5\n",
        "                   ,callbacks = [history])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "  17/3377 [..............................] - ETA: 6:17:06 - loss: 15.5966 - acc: 0.0324"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:872: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1345/3377 [==========>...................] - ETA: 3:52:00 - loss: 15.7828 - acc: 0.0207"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UFYpzSfRkL7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = range(0, len(history.losses))\n",
        "plt.plot(x, history.losses)\n",
        "plt.plot(x, history.accuracy)\n",
        "plt.xlabel('batches')\n",
        "plt.title('Loss and Accuracy')\n",
        "plt.legend(['losses', 'accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lkD2XN3VoN6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save the model"
      ]
    },
    {
      "metadata": {
        "id": "cerE2JXmgziv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create results directory if it doesn't exist"
      ]
    },
    {
      "metadata": {
        "id": "vg1XgLU6g3oT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "path_results=\"drive/My Drive/results/zolantz/\"\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2f6TraMBoQV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sb-BkVPwoQnj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "del model  # deletes the existing model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wa599XGW_IvC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the model from h5 file"
      ]
    },
    {
      "metadata": {
        "id": "LRcUZ2M_hOHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "load the model from the saved file"
      ]
    },
    {
      "metadata": {
        "id": "i52-Ozi5hNw7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "model = load_model('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Isq0Db2goaYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nk3Nyobeoa-9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"loss: \",train_loss, \"acc: \",  train_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8dFWjonWnxUD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test the model on the TestSet"
      ]
    },
    {
      "metadata": {
        "id": "UELxNiCInm_s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets evaluate our model on the test set :\n"
      ]
    },
    {
      "metadata": {
        "id": "g_xQJ64Ngcq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(x_batch,y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhC4eOeD-ON1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_loss)\n",
        "print(train_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
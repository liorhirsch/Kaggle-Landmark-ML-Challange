{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainData on our NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "wjYSR_w8gBxb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liorhirsch/Kaggle-Landmark-ML-Challange/blob/master/Custom%20NN/Our-NN-Ready-for-execution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ovCIfYJru02G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Configuring the environment either to local or remote usage"
      ]
    },
    {
      "metadata": {
        "id": "sy6bXJaTuzzO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BASE_PATH='drive/My Drive'\n",
        "# BASE_PATH=\"E:/Projects/ML_Project/Landmark_Kaggle_Challange\"\n",
        "MODEL_NAME = \"1.0\"\n",
        "\n",
        "TRAINING_DATA_DIR = BASE_PATH + '/photos'\n",
        "VALIDATION_DATA_DIR = BASE_PATH + '/validation'\n",
        "TEST_DATA_PATH = BASE_PATH + '/test'\n",
        "\n",
        "MODEL_ENDING = \".H5\"\n",
        "\n",
        "RESULTS_PATH=BASE_PATH + \"/results/\"\n",
        "SAVING_DIR_PATH=BASE_PATH + \"/models/\"\n",
        "FULL_SAVING_PATH = SAVING_DIR_PATH + MODEL_NAME + MODEL_ENDING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjYSR_w8gBxb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload data from google drive"
      ]
    },
    {
      "metadata": {
        "id": "XM-4Y_2pgGwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1030
        },
        "outputId": "ad363a47-e4a0-4b5a-8506-42ddefce4e41"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-636f7e70c0f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount)\u001b[0m\n\u001b[1;32m    135\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m       \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendcontrol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Stopped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Y8EnxVkGgNqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build training data\n"
      ]
    },
    {
      "metadata": {
        "id": "Njiw9oQjgG83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbyGSja5O8VP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Augmentated Data Generation**\n",
        "\n",
        "Creates images generators both for the test and the training data, to create additional data"
      ]
    },
    {
      "metadata": {
        "id": "zi7O9h8zPh-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W--6UpdkNdQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "                              rotation_range=0,\n",
        "                              width_shift_range=0,\n",
        "                               height_shift_range=0,\n",
        "                               shear_range=0,\n",
        "                               zoom_range=[0.8, 1.25],\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=False,\n",
        "                               fill_mode='reflect',\n",
        "                               data_format='channels_last',\n",
        "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                               rotation_range=30,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               shear_range=0.01,\n",
        "                               zoom_range=[0.8, 1.25],\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=False,\n",
        "                               fill_mode='reflect',\n",
        "                               data_format='channels_last',\n",
        "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnVfTbjsP1vt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Uses the data as a stream object to enable batching on it instead of loading them all together to the ram using the ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "9VIoOKh5MuWo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_size = (100,100)\n",
        "batch_size = 20\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(TRAINING_DATA_DIR,\n",
        "                                                 target_size=image_size,\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                                        VALIDATION_DATA_DIR,\n",
        "                                         target_size=image_size,\n",
        "                                         color_mode='rgb',\n",
        "                                        class_mode = \"categorical\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FpVCqwfgQWlo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "# print(x_batch) # RGB 2d array\n",
        "# print(y_batch) # The label (class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPZsMdzOQcWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "# plt.figure(figsize=(20, 20))\n",
        "# for i in range(10):\n",
        "#     plt.subplot(5,2,i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     image = x_batch[i]\n",
        "#     image= image.astype(np.uint8)\n",
        "#     plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YENKwn2gd7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build The Network"
      ]
    },
    {
      "metadata": {
        "id": "Fj9gq5NfgR41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8F-7H5-jskL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Normalize the images.**"
      ]
    },
    {
      "metadata": {
        "id": "1QHRjCbcgjCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_batch = x_batch/255.0\n",
        "# print(x_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OxDR9s8vi5zN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build the NN**"
      ]
    },
    {
      "metadata": {
        "id": "PwvyevDngjFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape = x_batch.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Flatening the data\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNr7qLyugjGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ImGYYAj0jDX8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use Adam Optimizer to..."
      ]
    },
    {
      "metadata": {
        "id": "oaRupgnwgjIq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adamOptimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam',\\\n",
        "#  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kI8CcMtF7wsI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We convert the generator's output from binary array that contains 1 in the related class, to array contains the indexes of the classes for each picture in the batch"
      ]
    },
    {
      "metadata": {
        "id": "Lhc3bmSaPjJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y=[a.tolist().index(1) for a in y_batch];\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xoMiVWuDjRsU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "fpPYRBMgjsGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us configure a loss function and optimizer.\n",
        "\n",
        "The generator gives us in y a vector contains match percentages for each label, so we want to change it to show 0 or 1 using caregorical_crossentropy"
      ]
    },
    {
      "metadata": {
        "id": "Pg0VC_gnjj6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUzxicT-jueQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "we calculate the amount of batches in an ephoch (For fitting the model)"
      ]
    },
    {
      "metadata": {
        "id": "GAOigFXljyPx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "print(step_size_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rmchE3Avjzyl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We would like to observe the loss function values throught the training process. \n",
        "This is why we create a callback to store the loss and accuracy function values for each batch :"
      ]
    },
    {
      "metadata": {
        "id": "tlZzhz19j1Ny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LossAccHistory(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses = []\n",
        "        self.accuracy = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.accuracy.append(logs.get('acc'))\n",
        "        \n",
        "history = LossAccHistory()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kdxhXhlFBt7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fix for the error : \n",
        "OSError: image file is truncated (14 bytes not processed)"
      ]
    },
    {
      "metadata": {
        "id": "gF5dHsZSBqEx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True \n",
        "\n",
        "#https://stackoverflow.com/questions/12984426/python-pil-ioerror-image-file-truncated-with-big-images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q7aI5NDurIrB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define an early stopper to avoid wasting compute resources and time"
      ]
    },
    {
      "metadata": {
        "id": "ppvNHi7krH7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2Fs2chOrPtw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "networkfileName = RESULTS_PATH + \"/\" + MODEL_NAME + \"{}\" + MODEL_ENDING.format(int(time.time()))\n",
        "                      \n",
        "checkpoint = ModelCheckpoint(networkfileName, monitor='val_acc', verbose=1,\n",
        "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HfysIFiHj6Rz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we train the model with fit_generator instead of regular fit."
      ]
    },
    {
      "metadata": {
        "id": "rIqYAT_Kj9lm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(generator=train_generator,\n",
        "                   steps_per_epoch=step_size_train, # step=how much batches in one epoc\n",
        "                   validation_data = validation_generator,\n",
        "                   epochs=5\n",
        "                   ,callbacks = [checkpoint, early, history])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2S_FBNGesa83",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Examine the results"
      ]
    },
    {
      "metadata": {
        "id": "UFYpzSfRkL7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A8NihPX5sNL7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lkD2XN3VoN6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save the model"
      ]
    },
    {
      "metadata": {
        "id": "cerE2JXmgziv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create results directory if it doesn't exist"
      ]
    },
    {
      "metadata": {
        "id": "vg1XgLU6g3oT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(SAVING_DIR_PATH):\n",
        "    os.makedirs(SAVING_DIR_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2f6TraMBoQV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sb-BkVPwoQnj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(FULL_SAVING_PATH)  # creates a HDF5 file 'my_model.h5'\n",
        "del model  # deletes the existing model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wa599XGW_IvC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the model from h5 file"
      ]
    },
    {
      "metadata": {
        "id": "LRcUZ2M_hOHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "load the model from the saved file"
      ]
    },
    {
      "metadata": {
        "id": "i52-Ozi5hNw7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "model = load_model(FULL_SAVING_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Isq0Db2goaYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nk3Nyobeoa-9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"loss: \",train_loss, \"acc: \",  train_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8dFWjonWnxUD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test the model on the TestSet"
      ]
    },
    {
      "metadata": {
        "id": "UELxNiCInm_s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets evaluate our model on the test set :\n"
      ]
    },
    {
      "metadata": {
        "id": "g_xQJ64Ngcq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(x_batch,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brNgZlmZsfUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator()\n",
        "test_generator=test_datagen.flow_from_directory(TEST_DATA_PATH,\n",
        "                                                  target_size=image_size,\n",
        "                                                  color_mode='rgb',\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical')\n",
        "\n",
        "step_size_test=test_generator.n//test_generator.batch_size\n",
        "\n",
        "test_loss, test_acc = model_final.evaluate_generator(generator=test_generator, \n",
        "                               steps=step_size_test)\n",
        "                               \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhC4eOeD-ON1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_loss)\n",
        "print(train_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainData on our NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "wjYSR_w8gBxb"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liorhirsch/Kaggle-Landmark-ML-Challange/blob/master/our_custom_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wjYSR_w8gBxb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload data from google drive"
      ]
    },
    {
      "metadata": {
        "id": "XM-4Y_2pgGwJ",
        "colab_type": "code",
        "outputId": "db277155-cc09-4278-9e98-19bcf6789f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y8EnxVkGgNqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build training data\n"
      ]
    },
    {
      "metadata": {
        "id": "Njiw9oQjgG83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SiuTfoKxiTHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Upload to memory all the photos.**\n",
        "\n",
        "The data will be array of arrays. Each sub-array represents one landmark and will contain tuples of landmark photo and landmark id."
      ]
    },
    {
      "metadata": {
        "id": "qJIgoLh7gRvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "6e4461c2-de5f-4264-fa41-cee61e8ae23b"
      },
      "cell_type": "code",
      "source": [
        "DATADIR = \"drive/My Drive/photos/\"\n",
        "CATEGORIES =  os.listdir(DATADIR);\n",
        "print('Found %d categories in : %s' % (len(CATEGORIES), DATADIR))\n",
        "training_data = []\n",
        "IMG_SIZE = 100\n",
        "   \n",
        "def create_training_data(category):\n",
        "    data = []\n",
        "    print(\"Building training data for landmark id %s\" %category);\n",
        "    path = os.path.join(DATADIR, category)  # path tolandmark photos\n",
        "    landmark_id = category\n",
        "    for img in os.listdir(path):\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "            data.append([new_array, landmark_id])\n",
        "        except Exception as e:\n",
        "            pass   # do nothing\n",
        "    return data;\n",
        "          \n",
        "num_cores = multiprocessing.cpu_count();\n",
        "print('building the training data on %d cores' % num_cores)\n",
        "training_data_nested=Parallel(n_jobs=num_cores)(delayed(create_training_data)(category) for category in CATEGORIES)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100 categories in : drive/My Drive/photos/\n",
            "building the training data on 2 cores\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f6ea3108a8c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mnum_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'building the training data on %d cores'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtraining_data_nested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_training_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCATEGORIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/joblib/externals/loky/_base.pyc\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jbyGSja5O8VP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Augmentated Data Generation**\n",
        "\n",
        "Creates images generators both for the test and the training data, to create additional data"
      ]
    },
    {
      "metadata": {
        "id": "zi7O9h8zPh-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W--6UpdkNdQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "                              rotation_range=0,\n",
        "                              width_shift_range=0,\n",
        "                               height_shift_range=0,\n",
        "                               shear_range=0,\n",
        "                               zoom_range=[0.8, 1.25],\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=False,\n",
        "                               fill_mode='reflect',\n",
        "                               data_format='channels_last',\n",
        "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                               rotation_range=30,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               shear_range=0.01,\n",
        "                               zoom_range=[0.8, 1.25],\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=False,\n",
        "                               fill_mode='reflect',\n",
        "                               data_format='channels_last',\n",
        "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnVfTbjsP1vt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Uses the data as a stream object to enable batching on it instead of loading them all together to the ram using the ImageDataGenerator"
      ]
    },
    {
      "metadata": {
        "id": "9VIoOKh5MuWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5a385bbb-6e4a-4ea5-f307-ca228f75f649"
      },
      "cell_type": "code",
      "source": [
        "image_size = (100,100)\n",
        "batch_size = 10\n",
        "\n",
        "training_data_dir = 'drive/My Drive/photos'\n",
        "validation_data_dir = 'drive/My Drive/test'\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(training_data_dir,\n",
        "                                                 target_size=image_size,\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                                        validation_data_dir,\n",
        "                                         target_size=image_size,\n",
        "                                         color_mode='rgb',\n",
        "                                        class_mode = \"categorical\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 75315 images belonging to 100 classes.\n",
            "Found 18780 images belonging to 100 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FpVCqwfgQWlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6014
        },
        "outputId": "4b88ef09-b518-4099-fdb7-c1b6efc8a188"
      },
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "print(x_batch)\n",
        "print(y_batch)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[130. 191. 255.]\n",
            "   [131. 190. 255.]\n",
            "   [130. 191. 255.]\n",
            "   ...\n",
            "   [ 91. 121. 193.]\n",
            "   [ 32.  50. 122.]\n",
            "   [ 83. 104. 154.]]\n",
            "\n",
            "  [[130. 191. 255.]\n",
            "   [133. 191. 255.]\n",
            "   [131. 191. 255.]\n",
            "   ...\n",
            "   [ 49.  73. 148.]\n",
            "   [ 37.  61. 131.]\n",
            "   [101. 127. 175.]]\n",
            "\n",
            "  [[131. 191. 255.]\n",
            "   [133. 193. 255.]\n",
            "   [133. 194. 255.]\n",
            "   ...\n",
            "   [ 37.  56. 137.]\n",
            "   [ 64.  95. 157.]\n",
            "   [ 56.  71. 145.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[218. 220. 209.]\n",
            "   [ 73.  70.  79.]\n",
            "   [ 22.  10.  40.]\n",
            "   ...\n",
            "   [214. 215. 218.]\n",
            "   [208. 209. 212.]\n",
            "   [190. 191. 194.]]\n",
            "\n",
            "  [[161. 161. 163.]\n",
            "   [ 98.  95. 104.]\n",
            "   [ 13.   8.  28.]\n",
            "   ...\n",
            "   [200. 202. 205.]\n",
            "   [203. 205. 208.]\n",
            "   [191. 191. 194.]]\n",
            "\n",
            "  [[122. 122. 127.]\n",
            "   [ 89.  89.  95.]\n",
            "   [ 20.  20.  31.]\n",
            "   ...\n",
            "   [190. 191. 196.]\n",
            "   [190. 191. 196.]\n",
            "   [203. 205. 209.]]]\n",
            "\n",
            "\n",
            " [[[255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   ...\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]]\n",
            "\n",
            "  [[255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   ...\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]]\n",
            "\n",
            "  [[255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   ...\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]\n",
            "   [255. 255. 255.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 80.  86.  88.]\n",
            "   [ 54.  57.  59.]\n",
            "   [ 59.  69.  71.]\n",
            "   ...\n",
            "   [ 75.  89.  83.]\n",
            "   [ 51.  59.  56.]\n",
            "   [103. 115. 109.]]\n",
            "\n",
            "  [[ 78.  83.  86.]\n",
            "   [ 45.  49.  52.]\n",
            "   [ 55.  65.  68.]\n",
            "   ...\n",
            "   [ 78.  93.  85.]\n",
            "   [ 51.  64.  61.]\n",
            "   [ 85.  94.  92.]]\n",
            "\n",
            "  [[ 78.  86.  90.]\n",
            "   [ 45.  50.  54.]\n",
            "   [ 55.  65.  68.]\n",
            "   ...\n",
            "   [ 85.  99.  90.]\n",
            "   [ 63.  74.  69.]\n",
            "   [ 68.  78.  76.]]]\n",
            "\n",
            "\n",
            " [[[ 40. 150. 249.]\n",
            "   [ 44. 145. 248.]\n",
            "   [ 44. 143. 246.]\n",
            "   ...\n",
            "   [ 11. 128. 233.]\n",
            "   [ 11. 128. 233.]\n",
            "   [ 15. 126. 231.]]\n",
            "\n",
            "  [[ 42. 150. 250.]\n",
            "   [ 42. 149. 250.]\n",
            "   [ 42. 149. 250.]\n",
            "   ...\n",
            "   [  6. 130. 236.]\n",
            "   [  6. 130. 237.]\n",
            "   [ 13. 128. 231.]]\n",
            "\n",
            "  [[ 23. 137. 245.]\n",
            "   [ 21. 134. 241.]\n",
            "   [ 21. 134. 241.]\n",
            "   ...\n",
            "   [  7. 132. 244.]\n",
            "   [  6. 130. 245.]\n",
            "   [ 25. 126. 228.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 63.  76.  39.]\n",
            "   [ 58.  72.  42.]\n",
            "   [ 58.  71.  39.]\n",
            "   ...\n",
            "   [ 59.  54.  35.]\n",
            "   [ 56.  51.  33.]\n",
            "   [ 38.  34.  15.]]\n",
            "\n",
            "  [[ 22.  34.   9.]\n",
            "   [ 50.  66.  23.]\n",
            "   [ 56.  72.  29.]\n",
            "   ...\n",
            "   [ 72.  67.  42.]\n",
            "   [ 71.  66.  42.]\n",
            "   [ 38.  34.  21.]]\n",
            "\n",
            "  [[ 47.  58.  43.]\n",
            "   [ 50.  63.  35.]\n",
            "   [ 47.  60.  34.]\n",
            "   ...\n",
            "   [ 68.  67.  50.]\n",
            "   [ 67.  66.  50.]\n",
            "   [ 44.  36.  30.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   ...\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]]\n",
            "\n",
            "  [[164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   ...\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]]\n",
            "\n",
            "  [[164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   ...\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]\n",
            "   [164. 164. 164.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 99.  93.  83.]\n",
            "   [104.  94.  83.]\n",
            "   [ 95.  92.  76.]\n",
            "   ...\n",
            "   [117. 119. 117.]\n",
            "   [122. 123. 120.]\n",
            "   [125. 125. 122.]]\n",
            "\n",
            "  [[107.  99.  87.]\n",
            "   [103.  92.  87.]\n",
            "   [ 96.  90.  79.]\n",
            "   ...\n",
            "   [134. 135. 133.]\n",
            "   [128. 129. 126.]\n",
            "   [125. 126. 123.]]\n",
            "\n",
            "  [[110. 101.  90.]\n",
            "   [110.  99.  90.]\n",
            "   [ 96.  91.  78.]\n",
            "   ...\n",
            "   [121. 121. 119.]\n",
            "   [125. 126. 125.]\n",
            "   [131. 132. 129.]]]\n",
            "\n",
            "\n",
            " [[[ 95. 119. 144.]\n",
            "   [ 94. 120. 145.]\n",
            "   [ 95. 121. 147.]\n",
            "   ...\n",
            "   [145. 142. 146.]\n",
            "   [122. 133. 148.]\n",
            "   [111. 128. 147.]]\n",
            "\n",
            "  [[ 91. 116. 143.]\n",
            "   [ 92. 119. 146.]\n",
            "   [ 94. 121. 148.]\n",
            "   ...\n",
            "   [118. 130. 149.]\n",
            "   [104. 127. 150.]\n",
            "   [ 99. 123. 148.]]\n",
            "\n",
            "  [[ 90. 116. 143.]\n",
            "   [ 91. 118. 145.]\n",
            "   [ 95. 121. 148.]\n",
            "   ...\n",
            "   [ 98. 124. 149.]\n",
            "   [ 98. 123. 149.]\n",
            "   [ 98. 123. 149.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 68.  55.  45.]\n",
            "   [ 68.  53.  47.]\n",
            "   [ 65.  53.  47.]\n",
            "   ...\n",
            "   [101.  78.  48.]\n",
            "   [149. 108.  81.]\n",
            "   [ 99.  58.  42.]]\n",
            "\n",
            "  [[ 79.  60.  48.]\n",
            "   [ 64.  47.  42.]\n",
            "   [ 75.  58.  52.]\n",
            "   ...\n",
            "   [ 75.  49.  35.]\n",
            "   [ 81.  52.  34.]\n",
            "   [145. 121.  89.]]\n",
            "\n",
            "  [[ 97.  82.  68.]\n",
            "   [ 59.  45.  32.]\n",
            "   [ 68.  49.  38.]\n",
            "   ...\n",
            "   [ 85.  62.  45.]\n",
            "   [ 76.  53.  38.]\n",
            "   [ 45.  32.  19.]]]\n",
            "\n",
            "\n",
            " [[[149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   ...\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]]\n",
            "\n",
            "  [[149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   ...\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]]\n",
            "\n",
            "  [[149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   ...\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]\n",
            "   [149. 149. 149.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 32.  22.  25.]\n",
            "   [ 17.  13.  13.]\n",
            "   [ 20.  17.  17.]\n",
            "   ...\n",
            "   [ 80.  67.  71.]\n",
            "   [ 74.  55.  62.]\n",
            "   [ 65.  52.  59.]]\n",
            "\n",
            "  [[ 19.  16.  17.]\n",
            "   [ 21.  20.  26.]\n",
            "   [ 30.  31.  39.]\n",
            "   ...\n",
            "   [ 61.  48.  49.]\n",
            "   [ 71.  59.  68.]\n",
            "   [ 91.  71.  85.]]\n",
            "\n",
            "  [[ 38.  38.  55.]\n",
            "   [ 37.  41.  59.]\n",
            "   [ 42.  47.  69.]\n",
            "   ...\n",
            "   [ 77.  57.  65.]\n",
            "   [ 68.  52.  61.]\n",
            "   [ 80.  61.  72.]]]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TPZsMdzOQcWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "48ca1fbd-2ac0-4151-9730-0197e57de0cb"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    image = x_batch[i]\n",
        "    image= image.astype(type(ctypes.c_float))\n",
        "    plt.imshow(image)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-3ff3289667ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3099\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3101\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3102\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5129\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5131\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5132\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    616\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    617\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         if not (self._A.ndim == 2\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAADJCAYAAACJxhYFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAAjNJREFUeJzt2DEOwkAMAEEO0VLm/w9MyQPMByBb\nJlJmSl/jZmXp1sw8gP+eZy8AVycSCCKBIBIIIoHwOnrc94+vL25j297r19wlgSASCCKBIBIIIoEg\nEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBII\nIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKB\nIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSAS\nCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggi\ngSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEg\nEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBII\nIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKB\nIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigSASCCKBIBIIIoEgEggigbBm\n5uwd4NJcEggigSASCCKBIBIIIoHwBaWrC402t6+HAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5d93efc3d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OREutK_Ni_wV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FlatMap the data.**\n",
        "\n",
        "After this proccess, there will be a list of tuples. each tuple contain image and id of single landmark."
      ]
    },
    {
      "metadata": {
        "id": "m6KKjoAFgRxf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_data_with_real_ids=[landmark_id_pair for landmark_photos in training_data_nested for landmark_id_pair in landmark_photos]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfEyC_JyHyje",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create new ids for each landmark id**\n",
        "\n",
        "Keras can only work when the last layer of nuerons has the max value of the data id.\n",
        "So, if there is a landmark id that its value is 20000 than, the last layer must have at least 20000 neurons.\n",
        "In order to make the last layer with 100 neurons, we should generate new id for each landmark from 0 to 99.\n"
      ]
    },
    {
      "metadata": {
        "id": "Km8Z_K4gGGnQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_keys = [id for image, id in training_data_with_real_ids];\n",
        "unique_keys = set(all_keys);\n",
        "ids_dictionary = {};\n",
        "\n",
        "\n",
        "for idx, curr_id in enumerate(unique_keys):\n",
        "  ids_dictionary[curr_id] = idx\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Umm8TdTWJw5q",
        "colab_type": "code",
        "outputId": "37e736e9-6994-4c5f-dbac-ec71c03aaeca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(ids_dictionary['11249'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ep4DJt1DIuzA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Assign new id to each landmark in the training data.**"
      ]
    },
    {
      "metadata": {
        "id": "RKaauSuLIuXQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_data = [ [image, ids_dictionary[id] ] for image, id in training_data_with_real_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lpgV_2fkgR0D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FbnSMmwFjWln",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the training data as expected to keras library.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p0EfStKMgR2L",
        "colab_type": "code",
        "outputId": "fa67e60f-b31e-4d69-f8c8-2c0909c45784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(int(label))\n",
        "\n",
        "# We need to convert the List of images to a numpy array for Tensorflow\n",
        "# We create a numpy array where the image is in the shape of (50,50,1). 1 since this is a gray scale\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "print(X[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7YENKwn2gd7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "Fj9gq5NfgR41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Conv3D\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8F-7H5-jskL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Normalize the images.**"
      ]
    },
    {
      "metadata": {
        "id": "1QHRjCbcgjCO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = X/255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PwvyevDngjFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Flatening the data\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KNr7qLyugjGq",
        "colab_type": "code",
        "outputId": "840756e9-f7f9-41e0-8adc-c2507934d4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 98, 98, 64)        640       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 98, 98, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 49, 49, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 47, 47, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 47, 47, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 150)               5078550   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               15100     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 5,131,218\n",
            "Trainable params: 5,131,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oaRupgnwgjIq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adamOptimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', \n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam',\\\n",
        "#  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAe8BNF6gjKd",
        "colab_type": "code",
        "outputId": "16fa82ce-9668-4e65-e4c0-38a655955959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(X, y, batch_size=32, epochs = 30, validation_split=0.1)\n",
        "\n",
        "# model.fit(X, y, batch_size=64, epochs=1, verbose=1, \\\n",
        "# validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9049 samples, validate on 1006 samples\n",
            "Epoch 1/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 1.2049 - acc: 0.7001 - val_loss: 4.9783 - val_acc: 0.1660\n",
            "Epoch 2/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.3762 - acc: 0.9125 - val_loss: 6.1722 - val_acc: 0.1700\n",
            "Epoch 3/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.1261 - acc: 0.9752 - val_loss: 7.1375 - val_acc: 0.1670\n",
            "Epoch 4/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0503 - acc: 0.9939 - val_loss: 7.6738 - val_acc: 0.1640\n",
            "Epoch 5/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0445 - acc: 0.9938 - val_loss: 8.0054 - val_acc: 0.1581\n",
            "Epoch 6/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0554 - acc: 0.9896 - val_loss: 7.9130 - val_acc: 0.1521\n",
            "Epoch 7/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.1148 - acc: 0.9708 - val_loss: 7.8337 - val_acc: 0.1521\n",
            "Epoch 8/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.1010 - acc: 0.9756 - val_loss: 8.3258 - val_acc: 0.1531\n",
            "Epoch 9/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0728 - acc: 0.9838 - val_loss: 8.5298 - val_acc: 0.1600\n",
            "Epoch 10/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0371 - acc: 0.9923 - val_loss: 8.8633 - val_acc: 0.1481\n",
            "Epoch 11/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0384 - acc: 0.9910 - val_loss: 8.9104 - val_acc: 0.1441\n",
            "Epoch 12/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0486 - acc: 0.9891 - val_loss: 8.9792 - val_acc: 0.1362\n",
            "Epoch 13/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0620 - acc: 0.9860 - val_loss: 8.9289 - val_acc: 0.1521\n",
            "Epoch 14/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0504 - acc: 0.9885 - val_loss: 9.1979 - val_acc: 0.1501\n",
            "Epoch 15/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0168 - acc: 0.9966 - val_loss: 9.2679 - val_acc: 0.1581\n",
            "Epoch 16/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0098 - acc: 0.9988 - val_loss: 9.3816 - val_acc: 0.1600\n",
            "Epoch 17/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0086 - acc: 0.9988 - val_loss: 9.4520 - val_acc: 0.1650\n",
            "Epoch 18/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0083 - acc: 0.9989 - val_loss: 9.4571 - val_acc: 0.1640\n",
            "Epoch 19/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0082 - acc: 0.9988 - val_loss: 9.4864 - val_acc: 0.1640\n",
            "Epoch 20/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0081 - acc: 0.9989 - val_loss: 9.5466 - val_acc: 0.1630\n",
            "Epoch 21/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0083 - acc: 0.9988 - val_loss: 9.5617 - val_acc: 0.1640\n",
            "Epoch 22/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0081 - acc: 0.9988 - val_loss: 9.5507 - val_acc: 0.1620\n",
            "Epoch 23/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0083 - acc: 0.9989 - val_loss: 9.5928 - val_acc: 0.1620\n",
            "Epoch 24/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0088 - acc: 0.9989 - val_loss: 9.7310 - val_acc: 0.1640\n",
            "Epoch 25/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.3258 - acc: 0.9168 - val_loss: 9.0701 - val_acc: 0.1322\n",
            "Epoch 26/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.1316 - acc: 0.9655 - val_loss: 8.9672 - val_acc: 0.1382\n",
            "Epoch 27/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0368 - acc: 0.9917 - val_loss: 9.2042 - val_acc: 0.1342\n",
            "Epoch 28/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0138 - acc: 0.9976 - val_loss: 9.3493 - val_acc: 0.1511\n",
            "Epoch 29/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0146 - acc: 0.9975 - val_loss: 9.5869 - val_acc: 0.1362\n",
            "Epoch 30/30\n",
            "9049/9049 [==============================] - 10s 1ms/step - loss: 0.0137 - acc: 0.9977 - val_loss: 9.7023 - val_acc: 0.1342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19e2dc4780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "g_xQJ64Ngcq9",
        "colab_type": "code",
        "outputId": "29732d2e-b4b7-4b73-fea2-8da6a4931ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(X,y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10055/10055 [==============================] - 4s 390us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fhC4eOeD-ON1",
        "colab_type": "code",
        "outputId": "b2353b62-565d-4a6f-e090-d1c1728470fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_loss)\n",
        "print(train_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9807335368920803\n",
            "0.9118846345190857\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}